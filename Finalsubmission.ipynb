{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a4c704",
   "metadata": {},
   "source": [
    "##### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb090b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"Data/train\")\n",
    "new_base_dir = pathlib.Path(\"Data/kaggle_dogs_vs_cats_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8a05c",
   "metadata": {},
   "source": [
    "##### EDA: Explore the data with relevant graphs, statistics and insights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff448c",
   "metadata": {},
   "source": [
    "##### importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1061928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026ef570",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = pathlib.Path('Data/kaggle_dogs_vs_cats_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d3621",
   "metadata": {},
   "source": [
    "##### Random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90e5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbers = np.random.normal(size=(1000, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63ee6314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1000, 16)\n",
      "float64\n",
      "[[-0.1706301   0.47733981  0.61086006 -0.6261309   1.78631815  1.30773067\n",
      "   0.06694159  1.0339029  -0.9839949   0.19575353 -0.6411     -0.06758709\n",
      "  -0.25074352  2.06607531 -0.00925246 -0.46160289]\n",
      " [ 0.28483996 -1.74353046  0.48621393 -0.06133071 -1.54852993 -1.09811719\n",
      "   0.25188295 -0.54953267  0.55153544  0.28611023  0.73873451  1.1710162\n",
      "   2.42646699 -0.04496869 -0.51304358  1.24591216]\n",
      " [-0.15045265  0.63594586 -0.31754799 -0.22527966 -0.3439997   1.57062705\n",
      "   0.98946492  0.77400065 -0.08795634  0.30756077  1.3059014  -0.61677542\n",
      "  -0.08327399 -1.16178349  2.37681339 -0.57664443]\n",
      " [-0.92365345  0.39030272 -2.36150109  0.97320394 -0.57373059 -0.71222249\n",
      "  -0.43301238 -0.95637883 -0.00853996  2.38565745 -0.82579108 -0.81363516\n",
      "  -0.09572037 -0.50016134 -0.26472383  0.95428346]]\n"
     ]
    }
   ],
   "source": [
    "print(type(random_numbers))\n",
    "print(random_numbers.shape)\n",
    "print(random_numbers.dtype)\n",
    "print(random_numbers[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd7cbc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "957f8f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fadd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(['A','B','C']):\n",
    "    print(i,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff898725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n",
      "(16,)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3227699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.1706301   0.47733981  0.61086006 -0.6261309   1.78631815  1.30773067\n",
      "  0.06694159  1.0339029  -0.9839949   0.19575353 -0.6411     -0.06758709\n",
      " -0.25074352  2.06607531 -0.00925246 -0.46160289], shape=(16,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[ 0.28483996 -1.74353046  0.48621393 -0.06133071 -1.54852993 -1.09811719\n",
      "  0.25188295 -0.54953267  0.55153544  0.28611023  0.73873451  1.1710162\n",
      "  2.42646699 -0.04496869 -0.51304358  1.24591216], shape=(16,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[-0.15045265  0.63594586 -0.31754799 -0.22527966 -0.3439997   1.57062705\n",
      "  0.98946492  0.77400065 -0.08795634  0.30756077  1.3059014  -0.61677542\n",
      " -0.08327399 -1.16178349  2.37681339 -0.57664443], shape=(16,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(dataset):\n",
    "    print(element)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58c1b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 16)\n",
      "(32, 16)\n",
      "(32, 16)\n"
     ]
    }
   ],
   "source": [
    "batched_dataset = dataset.batch(32)\n",
    "for i, element in enumerate(batched_dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ee918b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.batch_op._BatchDataset"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batched_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026e59e",
   "metadata": {},
   "source": [
    "##### Using Keras Utility Functions to Create a Dataset for Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc50128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ef4229",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f464dbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a61440",
   "metadata": {},
   "source": [
    "##### Displaying the shapes of the data and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce6a1c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (32, 180, 180, 3)\n",
      "labels batch shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_dataset:\n",
    "    print(\"data batch shape:\", data_batch.shape)\n",
    "    print(\"labels batch shape:\", labels_batch.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
