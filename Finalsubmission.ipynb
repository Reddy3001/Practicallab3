{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a4c704",
   "metadata": {},
   "source": [
    "##### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb090b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"Data/train\")\n",
    "new_base_dir = pathlib.Path(\"Data/kaggle_dogs_vs_cats_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8a05c",
   "metadata": {},
   "source": [
    "##### EDA: Explore the data with relevant graphs, statistics and insights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff448c",
   "metadata": {},
   "source": [
    "##### importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ef570",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = pathlib.Path('Data/kaggle_dogs_vs_cats_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d3621",
   "metadata": {},
   "source": [
    "##### Random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbers = np.random.normal(size=(1000, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(random_numbers))\n",
    "print(random_numbers.shape)\n",
    "print(random_numbers.dtype)\n",
    "print(random_numbers[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cbc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fadd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(['A','B','C']):\n",
    "    print(i,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff898725",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, element in enumerate(dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3227699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, element in enumerate(dataset):\n",
    "    print(element)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dataset = dataset.batch(32)\n",
    "for i, element in enumerate(batched_dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee918b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(batched_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026e59e",
   "metadata": {},
   "source": [
    "##### Using Keras Utility Functions to Create a Dataset for Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc50128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ef4229",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a61440",
   "metadata": {},
   "source": [
    "##### Displaying the shapes of the data and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_dataset:\n",
    "    print(\"data batch shape:\", data_batch.shape)\n",
    "    print(\"labels batch shape:\", labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2759c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b76d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data_batch[0].numpy().astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "# Preview random 5 images from each class in train set\n",
    "def plot_sample_images(directory, label, n=5):\n",
    "    path = os.path.join(directory, label)\n",
    "    images = random.sample(os.listdir(path), n)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(15,5))\n",
    "    for img_name, ax in zip(images, axes):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        img = mpimg.imread(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_sample_images('Data/kaggle_dogs_vs_cats_small/train','cat')\n",
    "plot_sample_images('Data/kaggle_dogs_vs_cats_small/train','dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397723e",
   "metadata": {},
   "source": [
    "##### Training the CNN for a real-world image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c26e02",
   "metadata": {},
   "source": [
    "##### Generating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    r'Data\\kaggle_dogs_vs_cats_small\\train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    r'Data\\kaggle_dogs_vs_cats_small\\validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a89db0",
   "metadata": {},
   "source": [
    "##### Defining the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e48e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b125927",
   "metadata": {},
   "source": [
    "##### Callbacks and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"cnn_best_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c810e",
   "metadata": {},
   "source": [
    "##### Doing the VGG16 and using it as Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f027001",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = pathlib.Path('Data/kaggle_dogs_vs_cats_small')\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2)\n",
    "])\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "vgg_model = keras.Model(inputs, outputs)\n",
    "vgg_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
    "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
    "test_features, test_labels =  get_features_and_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cacc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_ft = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"vgg16_finetune_best.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history_vgg = vgg_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks_ft\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94d76f",
   "metadata": {},
   "source": [
    "##### Fine tuning the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856da3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg_model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(1e-5), metrics=[\"accuracy\"])\n",
    "\n",
    "# Continue training for a few epochs to fine-tune\n",
    "history_fine = vgg_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks_ft\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cdcee5",
   "metadata": {},
   "source": [
    "##### Model Evaluation and Comparasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn = keras.models.load_model(\"cnn_best_model.keras\")\n",
    "best_vgg = keras.models.load_model(\"vgg16_finetune_best.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef62c5",
   "metadata": {},
   "source": [
    "##### The Accuracy scores are here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161262ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_loss, cnn_acc = best_cnn.evaluate(test_dataset)\n",
    "vgg_loss, vgg_acc = best_vgg.evaluate(test_dataset)\n",
    "print(f\"Custom CNN Test Accuracy: {cnn_acc:.3f}\")\n",
    "print(f\"VGG16 Fine-Tuned Test Accuracy: {vgg_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45b19d",
   "metadata": {},
   "source": [
    "##### Here the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "\n",
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_cnn_pred = []\n",
    "y_vgg_pred = []\n",
    "for images, labels in test_dataset:\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_cnn_pred.extend(best_cnn.predict(images).flatten())\n",
    "    y_vgg_pred.extend(best_vgg.predict(images).flatten())\n",
    "y_true = np.array(y_true)\n",
    "y_cnn_bin = np.array(y_cnn_pred) > 0.5\n",
    "y_vgg_bin = np.array(y_vgg_pred) > 0.5\n",
    "\n",
    "cm_cnn = confusion_matrix(y_true, y_cnn_bin)\n",
    "cm_vgg = confusion_matrix(y_true, y_vgg_bin)\n",
    "print(\"CNN Confusion Matrix:\\n\", cm_cnn)\n",
    "print(\"VGG Confusion Matrix:\\n\", cm_vgg)\n",
    "\n",
    "print(f'Custom CNN - Precision: {precision_score(y_true, y_cnn_bin):.2f}, Recall: {recall_score(y_true, y_cnn_bin):.2f}, F1: {f1_score(y_true, y_cnn_bin):.2f}')\n",
    "print(f'VGG16 Fine-Tuned - Precision: {precision_score(y_true, y_vgg_bin):.2f}, Recall: {recall_score(y_true, y_vgg_bin):.2f}, F1: {f1_score(y_true, y_vgg_bin):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67486108",
   "metadata": {},
   "source": [
    "##### Visiualizing the Precision-Recall curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c05c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_cnn = precision_recall_curve(y_true, y_cnn_pred)\n",
    "pr_vgg = precision_recall_curve(y_true, y_vgg_pred)\n",
    "\n",
    "plt.plot(pr_cnn[1], pr_cnn[0], label='Custom CNN')\n",
    "plt.plot(pr_vgg[1], pr_vgg[0], label='VGG16 Fine-Tuned')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b42cf",
   "metadata": {},
   "source": [
    "##### Checking the failure analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13557577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "failure_idxs = np.where((y_true != y_cnn_bin) | (y_true != y_vgg_bin))[0]\n",
    "print(f\"Number of incorrect predictions: {len(failure_idxs)}\")\n",
    "if len(failure_idxs) > 0:\n",
    "    ix = random.choice(failure_idxs)\n",
    "    for batch_images, batch_labels in test_dataset:\n",
    "        if ix < len(batch_labels):\n",
    "            img = batch_images[ix].numpy().astype(\"uint8\")\n",
    "            plt.imshow(img)\n",
    "            plt.title(\n",
    "                f\"True: {class_names[batch_labels[ix]]}, CNN: {class_names[int(y_cnn_bin[ix])]}, VGG: {class_names[int(y_vgg_bin[ix])]}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            break\n",
    "        ix -= len(batch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e171058",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "#### **Which model performed better? Why?**\n",
    "The VGG16 transfer learning model outperformed the custom CNN model in both accuracy and loss. This is because it leveraged pre-trained weights from ImageNet, allowing it to extract more complex and generalized features early in training.\n",
    "\n",
    "#### **How did transfer learning accelerate or improve learning?**\n",
    "Transfer learning significantly reduced the training time and improved convergence. The pre-trained layers already had a strong understanding of low-level patterns like edges and textures, enabling faster and more accurate learning on the Dogs vs Cats dataset.\n",
    "\n",
    "#### **Any clear signs of overfitting or underfitting? How did callbacks or augmentation help?**\n",
    "Some signs of overfitting were observed in the CNN model, especially when validation loss stopped improving. EarlyStopping and ModelCheckpoint helped mitigate overfitting, while data augmentation improved generalization by exposing the model to varied image patterns.\n",
    "\n",
    "#### **What types of images did both models struggle with?**\n",
    "Both models struggled with images where dogs and cats appeared in ambiguous poses, low lighting, or with significant occlusions. Misclassifications were common in close-up shots or where animals were partially visible.\n",
    "\n",
    "#### **What would be the next steps to further boost performance?**\n",
    "To boost performance, we could fine-tune deeper VGG16 layers, experiment with more powerful models like ResNet or EfficientNet, and optimize hyperparameters. Adding more data or using advanced augmentations could also improve generalization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
